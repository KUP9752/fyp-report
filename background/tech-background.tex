\section{End-to-End Learning for Robot Control}

  End-to-end refers to a robot learning approach where the robot determines certain \textbf{policies} (actions to perform a certain task) from raw inputs from the action space. The action space can include anything that we think the robot may benefit form knowing. This means the 
  robot learns to map sensory inputs directly to motor commands, bypassing the need for intermediate steps such as feature extraction or state estimation. This approach leverages deep learning techniques \cite{Schmidhuber2015nn}, particularly convolutional neural networks (CNNs) and recurrent neural networks (RNNs), to process high-dimensional sensory data and generate appropriate actions. Which can then be used in techniques like Reinforcement Learning \ref{sec:rl} or Imitation Learning \ref{sec:il}. Therefore, recent advancements in machine learning technologies has also reshaped the field of robotics and helps move it forward \cite{Pierson18082017,newbury2023graspSynthReview,liu2021DRLminireview}.

  \missingfigure{add 2 figures as a small outline like a blackbox + a few steps}

  This contrasts with the classical approaches\todo{citations here from the older theory papers maybe}. Classical robotics involves separating the behaviour of a robot into smaller tasks, where each task is managed by a distinct module and the system is functional when the pipeline comes together. Although good at precisely executing repetitive tasks, this approach requires complex and often handcrafted solutions for each module. This can lead to difficulties in scaling and adapting to new tasks or environments. 
  
  Therefore, the cutting-edge research in robotics concerns end-to-end systems in making multi-modal robots, which can be tuned for specific tasks if needed, using their capabilities of complex decision-making withing the given environments.

% Math Foundations
\input{background/tech-back/mf.tex}
% Reinforcement Learning
\input{background/tech-back/rl.tex}
% Imitation Learning
\input{background/tech-back/il.tex}
% Computer Vision 
\input{background/tech-back/cv.tex}
% Active Vision 
\input{background/tech-back/av.tex}
