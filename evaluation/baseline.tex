\subsection{Baseline - Naive Modality Concatenation}
This will be the baseline to compare the rest of the data. A hard set hyperparameter is the encoding CNN, for which the code can be found here \todo[color=green]{appendix code}. The input channel is dependent on the inputs. The layers of which are set to $\left[32, ~48, ~64, ~128\right]$ and the final encoding is of shape \(\langle 128, ~2, ~2 \rangle\).

\subsubsection{Grasp - Normal}
Firstly, I trained the policy with \textbf{normal} sizes. Looking at \ref{fig:base-grasp-final-normal}, it is clear that the `test' cases don't work very well. Surprisingly, the left and right shoulder combination is not amazing at this task, for `test` it laid completely above the $0.4$ line and was excluded from the final distance graph to allow enough resolution for the rest of the data. This is likely due to the distance of the shoulder cameras. The smaller target appears even smaller from further away, and likely harder to understand where it is. 

Otherwise the system was mostly consistent, reaching around $8$ to $10$ centimeters from the target, which is close but not very good. Which can be confirmed by looking at the success rates. The task does not have a singular success recorded for `test'. And `control' lingers around the average $9$\% rate per epoch, and 13\% at the best. This is unexpectedly low. Earlier grasping experiments conducted during development, namely in Section \ref{sec:grasping-tasks}, had higher success. 

However, this task is inherently harder due to the randomness. Therefore, I believe the grasping mechanisms might not be learning well enough in this version of the task. If, this is a trend, and not the baseline's fault, I might have to investigate why deeper.\todo{is it baselines fault,  (i dont think so) oh no is it the minibatch size?}

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{assets/evaluation/baseline/base-grasp-final.png}
  \caption{Final Distances Reached for the Grasp task (\textbf{normal})}\label{fig:base-grasp-final-normal}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[scale = 0.3]{assets/evaluation/baseline/base-grasp-control-success-cams-epochs.png}
  \caption{Success Rate (\%) of task per cam type over epochs \textbf{normal}}\label{fig:base-grasp-control-success-normal}
\end{figure}

\subsubsection{Grasp - Smaller}
Secondly, I flipped the parameters, trained on \textbf{smaller} and tested on \textbf{normal}. I have pruned the wrong test demos from the results, so there are only $7$ control `checks' and $10$ `test' checks. Looking at Figure \ref{fig:base-grasp-final-smaller}, We can see similar trends in the control being learnt better. This is expected due to the training set aligning better with the control set of checks. However, unlike the earlier graph, the agent learns to get closer to the target, especially using just the wrist RGB camera. `Test' again performs comparably worse, however, interestingly this performs as well as `control' from Figure \ref{fig:base-grasp-final-normal}, notice the scale differences in graphs. 

Disappointingly, but expectedly, the success is even worse. Figure \ref{fig:base-grasp-success-smaller}, shows that rarely any successes across epochs and seeds for either check. Meaning the plateau from the `control' final distances in \ref{fig:base-grasp-final-smaller}, must have been the agent smashing into the cube as there is no success for wrist RGB in that epoch range. \todo{put data from the grasping pics, this might be interesting here, do a number of grasp attempts versus successful grasps table here}

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{assets/evaluation/baseline/base-grasp-final-smaller.png}
  \caption{Final Distances Reached for the Grasp task (\textbf{smaller})}\label{fig:base-grasp-final-smaller}
\end{figure}

\begin{figure}[H]
  \centering
  \begin{subfigure}{0.45\linewidth}
    \centering
    \includegraphics[width=\linewidth]{assets/evaluation/baseline/base-smaller-grasp-control-success-cams-epochs.png}
    \caption{Grasp success for `Control' per Cam Type and Epochs }\label{subfig:base-grasp-control-success-smaller}
  \end{subfigure}
  \hfill
  \begin{subfigure}{0.45\linewidth}
    \centering
    \includegraphics[width=\linewidth]{assets/evaluation/baseline/base-smaller-grasp-test-success-cams-epochs.png}
    \caption{Grasp Success for `Test' per Cam Type and Epochs}\label{subfig:base-grasp-test-success-smaller}
  \end{subfigure}
  
  \caption{Grasp Success (\textbf{smaller}) (legends shared with Figure \ref{fig:base-grasp-final-smaller})}\label{fig:base-grasp-success-smaller}
\end{figure}\todo[color=blue]{these can be removed, and made into a table or just removed }


\subsubsection{Reach with Obstacle}
Final part of the evaluation is with the reaching task. Similarly to \todo{link to reachobs}, I will be mainly comparing minimum distances in this task to assess the ability to get past the obstacle. Figure \ref{fig:base-reach-dists}, shows that for example `wrist' along is plateau ung around $0.4$ this means that the obstacle on average 0.4 metres from the target in this test set, and the agent cannot get past and likely is pushing against the wall.

This is confirmed, in Figure \ref{fig:base-reach-success} as there isn't a single successful reach for the wrist RGB camera, however as before the other views are doing within their expected range.

\begin{figure}[H]
  \centering
  \includegraphics[width=\linewidth]{assets/evaluation/baseline/base-reach-dists.png}
  \caption{Average final and minimum distances reached}\label{fig:base-reach-dists}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\linewidth]{assets/evaluation/baseline/base-reach-success-cams-epochs.png}
  \caption{Reach success}\label{fig:base-reach-success}
\end{figure}