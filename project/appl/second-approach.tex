\section{Second Approach: View Emsembling}
Getting the agent to plan using its environment has the drawbacks of needing a lot of prior information about the task. Which leads to inherent coupling to tasks or environments.

What if we could inject the movement of the camera into the RLBench demo system, so the view uncertainty system can be modelled independently of the environment on the data we have received. In short the plan here is to get demos that have multiple observations per timestep (meaning multiple observation collections and not just multiple modalities.) Then we can train a model with inherent uncertainty models to estimate the best pose to be in before executing an action. In theory, this should help eliminate the need for geometrical priors.

\subsection{Proposed Approach}
Firstly the demonstration system needs to change to allow for multiple observations to be recorded for a single step in the action. The changed demonstration system will give demos as \( \mathcal{D} := \{\langle \{o_i^t\}_{i = 1}^{N}, a^t\rangle\}_{t = 1}^{T}\) for $N$ distinct observations per step in $T$. Then we can have any number of predictive models, $f_k$, which will use a random subset of each observation set per demo. But still use the entire demo in learning the action model. So a demo set \(\mathcal{D}_k = \{\{ \langle o_s^t, ~a^t \}_{s \in O_s} \}_{t = 1}^T\) can be constructed where \(O_s = \{o_i^t | s_{m, i} = \text{True}\}\) which are the set of selected demos. This selector can be represented in many way, for example: \(s_{m, i} \in \{\text{True}, \text{False}\}^{M \times N}\). All it does it select $m$ observations from the demo to be flattened later, it should select at least one, otherwise the linear constraints of trajectories I had so far will break.
To ensure that the training can be mirroring how models are trained so far, \(\hat{a}_k = f_k\left(o_i\right)\) during inference, where $o_i$ is the current live observation.

\subsubsection{Regression Ensembling}
There are multiple ways to ensemble regression models: bagging (bootstrap aggregation)\cite{Breiman1996}, boosting, Bayesian averaging methods (BMAs) \cite{saito2024uncertaintyquantificationmassmodels,tang2014towards}. I am mainly concerned about modeling the uncertainty so that we can guess when the current observation might not be enough. So a BMA which internally can account for the uncertainty by modelling it might be a good approach.

\subsubsection{Types of Uncertainty}
In an ensemble model there are different kinds of unknowns \cite{Gal2016Uncertainty, H_llermeier_2021, valdenegrotoro2022deeperlookaleatoricepistemic}. \textbf{epistemic} uncertainty, which comes from the gaps in our knowledge. In this case, not covering every possible valid state in our environment and only training on the demonstrations provided will contribute to this kind. The second, \textbf{aleatoric}, is solely statistical; it refers to the inherent randomness in the data. For example, when requesting a demo from RLBench, the trajectory calculation engine will sample points along the waypoints and will generate us a `random' path as there is a stochastic component, especially in getting a non-linear path. These two components are usually combined to represent `predictive' uncertainty. We can leverage this uncertainty to trigger a pose reselection when it might be needed.

Also, if we can separate the epistemic and aleatoric we can learn the gap in the knowledge, interpreting that as a model $f_k$ does not have enough information to solve this task. Therefore, we can use this as a better measure, a utility score as \ref{subsec:appl-first-proposed} proposes. Ensemble Quantile-Range (E-QR) \cite{ansari2024eqr} is a promising method, yet might have issues with my  knowledge bae size, these ideas will be explored during implementation

\subsubsection{Action Loop}
So the system will be modelled, when the voted visibility is good, if the models think it is not uncertain, we can move my taking some movement average of the returned values. However, when the uncertainty is high, we can then queue for pose sampling and get a new pose, without interacting with the ensemble at all. A subtle advantage this over \ref{sec:appl-1} is that we can train an ensemble on the poses to predict the utility of the of the pose before moving to it, which should speed up the system somewhat.

\subsection{Demonstration System Hijacking}

The \verb|Scene|'s demo collection method is complicated and intertwined. With the bad experience I had with RLBench non-deterministically stopping to work, I wanted to stay clear off it if I could. The first idea I had was, during creation of a demonstration. The task that is associated with the scene will be stepped. which means the \verb|<Task>.step()| function will be called.So the initial idea was to hook in here, every time the task environment was stepped I could move the gripper slightly. Using a similar method to \ref{sec:appl-first-choose-pose}, and then collate these into a demo once the task was complete. 

I had two major issues with this. Firstly, the call chain to get to \verb|<Task>.step()| is incredible deep, there are 4 class jumps: we go from the \verb|TaskEnvironment| to \verb|Scene| to \verb|PyRep| to finally our task. All of these carry an internal state of observations and what is visited, and no return values are used because of this. However, the task object is not necessarily persistent, it is a template that can be loaded and unloaded and is quite frequently. 
I also tried hijacking the demonstration recording system, however, the convoluted objective calls are still problematic here. Hooking onto the simulator creates cyclic call loops and this interconnectedness makes the system very fragile. I decided that, although promising, this approach would have to be left for the end of the project. Considering the tight timelines, I never had time to revisit this again.

\subsection{Remarks}
Finally, active learning paradigms can be employed here to teach the most uncertain models further, like continuous training, and a pseudo-boosting approach where the model can continuously train its uncertainty system from the sampled poses and not the demos. However, this is not in scope for this project. Might be interesting to explore these on future iterations of this project.