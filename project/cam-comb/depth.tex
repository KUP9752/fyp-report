\section{Depth Interfacing}\label{sec:depth-interfacing}
Understanding distance through depth interfacing is an important part of perception. Continuing from the drawn parallels to humans, we place object in our fields of vision by our two eyes. Stereo-vision, allows us to process two slightly different poses of a target object to reinforce our understanding of where that object is in the environment around us. Other information such as lighting (and shadows) may unconsciously help us as well. The main takeaway is that understanding distance to an object goes a long way in firstly understanding how to approach an object. There are a few ways to achieve this in robotics. In RLBench specifically is either to use two cameras (with a known distance between the two cameras to adjust poses with known intrinsics). However, RGB cameras are not the only things we have access to. We also we have a depth sensor.

This is because,active vision is to be able to use minimal amounts of viewpoints. In this scenario, I want to be able justify to use the wrist camera accompanied by the wrist depth sensor to replace any other workspace cameras. Therefore, it is important to study shortcomings of individual sensors with respect to others to understand how policies with limited access to sensors can be proficient at using them.

\subsection{Grasping with Varying Depths}
A grasping task makes sense for this experiment. Because unlike the reaching tasks from earlier, the robot will need slightly more precision in executing its grasp and actually grabbing the target. The task performer needs to figure out where an object is before attempting to grab it. So, I created a modified version of the simple grasping task where the target object's distance and scale can be externally varied to observe the behaviours of agents in a controlled manner.

\begin{figure}[htpb] % htpb allows all placement
  \centering
  \begin{subfigure}{0.4\linewidth}
    \centering
    \includegraphics[width=0.3\linewidth]{assets/depth-interfacing/normal-size-grasp.png}
    \caption{Normal Target Size}\label{subfig:normal-grasp}
  \end{subfigure}
  \begin{subfigure}{0.4\linewidth}
    \centering
    \includegraphics[width=0.3\linewidth]{assets/depth-interfacing/smaller-grasp.png}
    \caption{Smaller Target Size}\label{subfig:small-grasp}
  \end{subfigure}
  \caption{Visualisation of the Depth Interfacing experiment task}\label{fig:di-task}
\end{figure}

Figure \ref{fig:di-task}, is the general setup I am planning on using to evaluate the depth sensor versus a multi-view setup. Initial observations from the side clearly indicate that these are two different targets and will require different reach lengths before the agent can attempt to grab them.

\begin{figure}[htpb] % htpb allows all placement
  \centering
  \begin{subfigure}{0.2\linewidth}
    \centering
    \includegraphics[width=\linewidth]{assets/depth-interfacing/normal-size-wrist.png}
    \caption{Normal RGB}\label{subfig:normal-rgb}
  \end{subfigure}
  \begin{subfigure}{0.2\linewidth}
    \centering
    \includegraphics[width=\linewidth]{assets/depth-interfacing/smaller-wrist.png}
    \caption{Smaller RGB}\label{subfig:small-rgb}
  \end{subfigure}
  \begin{subfigure}{0.20\linewidth}
    \centering
    \includegraphics[width=\linewidth]{assets/depth-interfacing/normal-depth.png}
    \caption{Depth Mask}\label{subfig:normal-depth}
  \end{subfigure}
  \begin{subfigure}{0.20\linewidth}
    \centering
    \includegraphics[width=\linewidth]{assets/depth-interfacing/smaller-depth.png}
    \caption{Smaller Mask }\label{subfig:small-depth}
  \end{subfigure}
  \caption{Wrist RGB and Depth Masks for the tasks}\label{fig:di-rgb-vs-depth}
\end{figure}

However, as seen in the comparison in \ref{subfig:normal-rgb} and \ref{subfig:small-rgb}, the RGB outputs look practically the same, and will very likely produce extremely similar features after extraction. A way to differentiate them would be to utilise the wrist depth mask in this encoding. As shown in \ref{subfig:normal-depth} and \ref{subfig:small-depth}, they now carry different features in those areas. In the depth mask the darker colours indicate closer objects, and the information is encoded as floats. 

\begin{figure}[htpb] % htpb allows all placement
  \centering
  \begin{subfigure}{0.2\linewidth}
    \centering
    \includegraphics[width=\linewidth]{assets/depth-interfacing/normal-l_rgb.png}
    \caption{Normal Left}\label{subfig:normal-l-shoulder}
  \end{subfigure}
  \begin{subfigure}{0.2\linewidth}
    \centering
    \includegraphics[width=\linewidth]{assets/depth-interfacing/normal-r_rgb.png}
    \caption{Normal Right}\label{subfig:normal-r-shoulder}
  \end{subfigure}
  \begin{subfigure}{0.2\linewidth}
    \centering
    \includegraphics[width=\linewidth]{assets/depth-interfacing/smaller-l_rgb.png}
    \caption{Smaller Left}\label{subfig:smaller-l-shoulder}
  \end{subfigure}
  \begin{subfigure}{0.2\linewidth}
    \centering
    \includegraphics[width=\linewidth]{assets/depth-interfacing/smaller-r_rgb.png}
    \caption{Smaller Right}\label{subfig:smaller-r-shoulder}
  \end{subfigure}
  \caption{Left and Right Shoulder RGB Cameras}\label{fig:di-lr-shoulder}
\end{figure}


Another possible differentiating factor is the shoulder cameras. These also provide extra information about the scene the agent can use to understand its 3D geometry, even if it isn't explicitly taught. Although these are also not perfect, as seen in \ref{subfig:smaller-l-shoulder}, this camera is completely obstructed by the robot and is not seeing the target. This is not immediately problematic, because a smart enough system might be able to reason that the target is visible on the right and not on the left, leading to devising the correct depth for it.

% \subsubsection{Adding Stereo Wrist Vision}\todo[color=blue]{can be removed not sure}
% A possibility to overcome this \emph{self-occlusion} is to introduce stereo vision at the wrist level. Adding 2 off-centre cameras to the gripper, likely to the left and right of the existing wrist camera, will fix the self-occlusion, and possibly create a better comparison to the \emph{Wrist RGB} and \emph{Wrist Depth} combination. However, this comes with a lot of rewiring of RLBench and with its likely hidden issues that will pop up later. I did not want to take on this large architectural change before continuing with main investigation of the project, however, if timings permit this will be an important addition to the testing suite.
